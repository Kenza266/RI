{
    "0": "What problems and concerns are there in making up descriptive titles?\nWhat difficulties are involved in automatically retrieving articles from\napproximate titles?\nWhat is the usual relevance of the content of articles to their titles?",
    "1": "How can actually pertinent data, as opposed to references or entire articles\nthemselves, be retrieved automatically in response to information requests?",
    "2": "What is information science?  Give definitions where possible.",
    "3": "Image recognition and any other methods of automatically\ntransforming printed text into computer-ready form.",
    "4": "What special training will ordinary researchers and businessmen need for proper\ninformation management and unobstructed use of information retrieval systems?\nWhat problems are they likely to encounter?",
    "5": "What possibilities are there for verbal communication between computers and\nhumans, that is, communication via the spoken word?",
    "6": "Describe presently working and planned systems for publishing and printing\noriginal papers by computer, and then saving the byproduct, articles coded in\ndata-processing form, for further use in retrieval.",
    "7": "Describe information retrieval and indexing in other languages.\nWhat bearing does it have on the science in general?",
    "8": "What possibilities are there for automatic grammatical and contextual analysis\nof articles for inclusion in an information retrieval system?",
    "9": "The use of abstract mathematics in information retrieval, e.g. group theory.",
    "10": "What is the need for information consolidation, evaluation, and retrieval in\nscientific research?",
    "11": "Give methods for high speed publication, printing, and distribution of\nscientific journals.",
    "12": "What criteria have been developed for the objective evaluation of information\nretrieval and dissemination systems?",
    "13": "What future is there for automatic medical diagnosis?",
    "14": "How much do information retrieval and dissemination systems, as well as\nautomated libraries, cost?\nAre they worth it to the researcher and to industry?",
    "15": "What systems incorporate multiprogramming or remote stations in information\nretrieval?  What will be the extent of their use in the future?",
    "16": "Means of obtaining large volume, high speed, customer usable\ninformation retrieval output.",
    "17": "What methods are there for encoding, automatically matching,\nand automatically drawing structures extended in two dimensions,\nlike the structural formulas for chemical compounds?",
    "18": "Techniques of machine matching and machine searching systems.\nCoding and matching methods.",
    "19": "Testing automated information systems.",
    "20": "The need to provide personnel for the information field.",
    "21": "Automated information in the medical field.",
    "22": "Amount of use of books in libraries.\nRelation to need for automated information systems .",
    "23": "Educational and training requirements for personnel in the information field.\nPossibilities for this training.  Needs for programs providing this training.",
    "24": "International systems for exchange and dissemination of information.",
    "25": "Cost and determination of cost associated with systems of automated information.",
    "26": "Computerized information retrieval systems.  Computerized indexing systems.",
    "27": "Computerized information systems in fields related to chemistry.",
    "28": "Specific advantages of computerized index systems.",
    "29": "Information dissemination by journals and periodicals.",
    "30": "Information systems in the physical sciences.",
    "31": "Attempts at computerized and mechanized systems for general libraries.\nProblems and methods of automated general author and title indexing systems.",
    "32": "Retrieval systems which provide for the automated transmission of information\nto the user from a distance.",
    "33": "Methods of coding used in computerized index systems.",
    "34": "Government supported agencies and projects dealing with information dissemination.",
    "35": "What are some of the theories and practices in computer translating of\ntexts from one national language to another?  How can machine translating\ncompete with traditional methods of translating in comprehending nuances\nof meaning in languages of different structures?\n",
    "36": "What lists of words useful for indexing or classifying material are\navailable?  Wanted are lists of terms that are descriptive vocabularies\nof particular fields or schedules of words that are related to each other\nin meaningful schemes.  Wanted are lists that have been tested, at least to\nsome extent, and found useful for organizing material and for retrieving it.\n",
    "37": "How can access words in an information retrieval system be kept up to date?\nWord meanings and usage often change and lists must be dynamic to be current.\nWhat definitions of the problem and progress toward solutions have been made\nin providing necessary flexibility in systems of subject headings, index\nwords, or other symbols used for getting at stored data?\n",
    "38": "The progress of information retrieval presents problems of maladjustment\nand dislocation of personnel.  Training and retraining of people to use\nthe new equipment is important at all levels.  Librarians, assistants,\ntechnicians, students, researchers, and even executives will need education\nto learn the purpose, values, and uses of information systems and hardware.\nWhat programs have been developed to change the attitudes and skills of\ntraditional workers and help them to learn the newer techniques?\n",
    "39": "What is the status of machine translation?  What progress has been\nmade in the use of computers to transfer from one language to another\nwith some degree of automation?  What problems and stumbling blocks\nhave been found and are they considered to be insurmountable limitations\nor only challenging to the field of documentation on an international scale?\n",
    "40": "Is alphabetical ordering of material considered to be a useful tool in\ninformation retrieval?  What studies have been done to compare the\neffectiveness of alphabetical order with other organization schemes?\nIs there a generally accepted form of arranging material in\nalphabetical order, and is there an easy way of achieving this form\nwithout going to a great amount of effort?\n",
    "41": "The average student or researcher has difficulty in comprehending the\nvocabulary of information retrieval.  It appears important that this\nnew field be understood before it is to be fully accepted.  What basic\narticles would provide an understanding of the various important aspects\nof the information storage and retrieval?\n",
    "42": "The difficulties encountered in information retrieval systems are often\nless related to the equipment used than to the failure to plan\nadequately for document analysis, indexing, and machine coding.  The\nposition of the programmer is to take a problem and write it in a way\nin which the equipment will understand.  What articles have been written\ndescribing research in maximizing the effectiveness of programming?\n",
    "43": "There are presently fifty to one hundred technical journals being\npublished.  On the average, two new journals appear every day.  In\nthe many journals published, one to two million articles appear every\nyear.  What attempts have been made to cope with this amount of\nscientific and technical publication in terms of analysis, control,\nstorage, and retrieval?\n",
    "44": "I am looking for information about the impact of automation on\nlibraries and its significance for libraries in general.  This includes\nthe increasing importance of automation in view of the proliferation of\ninformation today, and how automation can help libraries cope with\nthis problem.  How will automation affect libraries and how should they\nreact to the idea of automation?\n",
    "45": "I am seeking information on the use of data processing in libraries and\nthe mechanization of routine library processes and procedures.  I would\nlike descriptions of both general and specific applications of\nautomation in such areas as circulation, cataloging, acquisitions,\nserial records, and other record-keeping.  Examples should be based on\nthe operation of a conventional public or university library, or\npractices in a special library which could also be applied in a public\nor university library.  Give descriptions of equipment and operations,\nboth present and projected.\n",
    "46": "Is there any established means at present for an international exchange\nof material about information retrieval?  If there is, does it take\nthe form of an international agency or center which regularly\ndistributes information retrieval methods and research results?  If\nthere is not, in what ways has this material crossed national\nboundaries?  What seem to have been some of the problems blocking a\nbetter international exchange, and is any effort being made to solve\nsome of those problems?\n",
    "47": "Information retrieval is still such a new and experimental field that a\nline distinguishing research and practice is often difficult - even\nimpossible - to draw.  Are there, however, actual centers of research\non information retrieval?  If so, in which countries are they\nlocated?  Who supports them - government, business, universities, or\nlibraries?  Can information retrieval as a specialized research\ndiscipline be said to be emerging, or is it still an amalgam of skills\nfrom other fields, such as mathematics, engineering, and library\nscience?  In other words, tell me about information retrieval research.\n",
    "48": "Most resources have been spent on applying information retrieval\ntechniques to the physical and medical sciences.  But, has information\nretrieval been used at all in the natural sciences, social sciences,\nand humanities?  If so, what have been some of the problems which have\nbeen encountered with these subject areas and how have they been\nsolved, if at all?  Have the characteristics of these subject areas\nnecessitated the development of new information retrieval techniques?\nWhat are the prospcts for future machine control in these areas?\n",
    "49": "Is there any use for traditional classification schemes - DDC, UDC, LC,\netc. - in information retrieval systems?  If there is, which scheme\nappears most suited to machine use and where has it been applied?\nIf there is not, why are these classification schemes irrelevant?\nHas research shown that a subject classification of knowledge is\ncompletely unnecessary in machine systems? Or, have new schemes\nbeen devised which appear to be more suited to machine use?\n",
    "50": "Coordinate indexing utilizes descriptors for controlled language.  Of\nwhat use are descriptors in the construction of an index?  How can\ndescriptors be used for searching in an information retrieval system?\n",
    "51": "What are the characteristics of MEDLARS (Medical Literature Analysis\nand Retrieval System) project which has been undertaken by the\nNational Library of Medicine?  How does it index current medical\njournals and of what relation is this indexing system to Index Medicus?\nWhat are the major components of the MEDLARS project and its major operating\ndetails?\n",
    "52": "How can the computer be used in medical science for diagnostic and\nclinical record keeping purposes?  Have any programs of automation\nbeen tried in hospitals?  If so, what have been the results?\nWhat problems have been encountered in the use of automation in\nmedicine?  For what purposes can an automated system of clinical\nrecords be used?  What are other possible uses of the computer in medicine?\n",
    "53": "What is the effect on librarians of automation?  Note the new types\nof technology to be used in the library which will have an effect on\nthe status, position, and function of the librarians.  What changes\nare being contemplated or have been initiated to introduce automation\ninto the education of librarians?\n",
    "54": "What are the aims and objectives of the medical literature analysis\nand retrieval system (MEDLARS)?  How does MEDLARS operate?  What are\nthe possible applications of MEDLARS to future information retrieval\nsystems?\n",
    "55": "The standard method of finding information in today's libraries is\nthrough the use of the alphabetically arranged card catalog or the\nclassified catalog based on a classification system such as the DC or\nLC.  Can these systems be modified for use with automated information\nretrieval?\n",
    "56": "In catalogs which are either arranged alphabetically or arranged by\nclassification number, the LC entry, printed in readable language, is\nultimately important because the individual looking for information\nhas a definite author, title, or subject phrase in his language\n(probably English in our case) in mind.  Will LC entries and subject\nheadings be used in the same manner in automated systems?\n\n\n",
    "57": "    Bibliographic control before and after MARC is reviewed.  The capability\nof keying into online systems brought an interdependence among libraries,\nthe service centers that mediate between them, and the large utilities that\nprocess and distribute data.  From this has developed the basic network\nstructure among libraries in the United States.  The independent development\nof major networks has brought problems in standardization and coordination.\nThe authors point out that while technology has led toward centralization\nof automated library services, new developments are now pushing toward\ndecentralization.  Coordination is a requirement to avoid fragmentation in\nthis new environment.",
    "58": "    The retrieval performance of book indexes can be measured in terms of\ntheir ability to direct a user selectively to text material whose identity\nbut not location is known.  The method requires human searchers to base\ntheir searching strategies on actual passages from the book rather than on\ntest queries, natural or contrived.  It circumvents the need for relevance\njudgement, but still yields performance indicators that correspond\napproximately to the recall and precision ratios of large document retrieval\nsystem evaluation.  A preliminary application of the method to the subject\nindexing of two major encyclopedias showed one encyclopedia apparently\nsuperior in both the finding and discrimination abilities of retrieval\nperformance.  The method is presently best suited for comparative testing\nsince its ability to yield absolute or reproducible measures is as yet not\nestablished.",
    "59": "    A linkage similarity measure which takes into account both the bibliographic\ncoupling of documents and their cocitations (both cited and citing papers)\nproduced improved document retrieval over a measure based only on\nbibliographic coupling.  The test collection consisted of 1712 papers whose\nrelevance to specific queries had been judged by users.  To evaluate the\neffect of using cocitation data, we calculated for each query two measures\nof similarity between each relevant paper and every other paper retrieved.\nPapers were then sorted by the similarity measures, producing two ordered\nlists.  We then compared the resulting predictions of relevance, partial\nrelevance, and non-relevance to the user's evaluations of the same papers.\nOverall, the change from the bibliographic coupling measure to the linkage\nsimilarity measure, representing the introduction of cocitation data,\nresulted in better retrieval performance.",
    "60": "    The way that individuals construct and modify search queries on a\nlarge interactive document retrieval system is subject to systematic biases\nsimilar to those that have been demonstrated in experiments on judgements\nunder uncertainty.  These biases are shared by both naive and sophisticated\nsubjects and cause the inquirer searching for documents on a large interactive\nsystem to construct and modify queries inefficiently.  A searching algorithm\nis suggested that helps the inquirer to avoid the effect of these biases.",
    "61": "    This article concerns the problem of how to permit a patron to\nrepresent the relative importance of various index terms in a Boolean\nrequest while retaining the desirable properties of a Boolean system.\nThe character of classical Boolean systems is reviewed and related to the\nnotion of fuzzy sets.  The fuzzy set concept then forms the basis of the\nconcept of a fuzzy request in which weights are assigned to index terms.\nTher properties of such a system are discussed, and it is shown that such\nsystems retain the manipulability of traditional Boolean requests.",
    "62": "    A commercially available online search was used as a standard for\ncomparative searching and evaluation of an in-house information system\nbased on automatic indexing.  System features were identified and\nevaluated on the basis of their usefulness in various kinds of searching,\ntheir ease in implementation, and how they are influenced by differences\nin user type or specific applications.  Some common features of the\ncommercial system, such as online instruction, user-specified print formats,\ndictionary display, and truncation, are seen to be unnecessary or\nimpractical for the in-house system.  In designing the in-house system,\ntherefore, detald consideration must be given to the applications,\noperating environment, and real user needs.  While a commercial system can\nserve as a useful standard for comparative evaluation, one must be\ncareful not to attempt to duplicate it blindly in-house.",
    "63": "    It is argued that in information science we have to distinguish\nphysical, objective, or document space from perspective, subjective, or\ninformation space.  These two spaces are like maps and landscapes: each\nis a systematic distortion of the other.  However, transformation can be\neasily made once the two spaces are distinguished.  If the transformations\nare omitted we only get unhelpful physical solutions to information problems.",
    "64": "    The use of document clusters has been suggested as an efficient file\norganization for a document retrieval system.  It is possible that by\nusing this information about the relationships between documents that the\neffectiveness of the system (i.e., its ability to distinguish relevant\nfrom non-relevant documents) may also be improved.  In this paper a\nprobabilistic model of cluster searching  based on query classification is\ndescribed.  This model is tested with retrieval experiments which indicate\nthat it can be more effective than heuristic cluster searches and cluster\nsearches based on other models.  It can also be more effective than a full\nsearch in which every document is compared to the query.  The efficiency\naspects of the implementation of the model are discussed.",
    "65": "    Current online library network technology is described, including the\nphysical and functional aspects of networks.  Three types of networks are\ndistinguished:  search service (e.g., SDC, Lockheed), customized service\nthat provide bibliographic files (e.g., OCLC, Inc., RLIN), and service\ncenter (e.g., NELINET, INCOLSA).  It is predicted that as technology\nevolves more services will be provided outside the library directly to the\nuser through his home or office.",
    "66": "    An experimental computer program has been developed to classify\ndocuments according to the 80 sections and five major section groupings of\nChemical Abstracts (CA).  The program uses pattern recognition techniques\nsupplemented by heuristics.  During the \"training\" phase, words from\npre-classified documents are selected, and the probability of occurrence\nof each word in each section of CA is computed and stored in a reference\ndictionary.  The \"classification\" phase matches each word of a document\ntitle against the dictionary and assigns a section number to the document\nusing weights derived from the probabilities in the dictionary.  Heuristic\ntechniques are used to normalize word variants such as plurals, past\ntenses, and gerunds in both the training phase and the classification\nphase.  The dictionary lookup technique is supplemented by the analysis of\nchemical nomenclature terms into their component word roots to influence\nthe section to which the documents are assigned.  Program performance and\nhuman consistency have been evaluated by comparing the program results\nagainst the published sections of CA and by conducting an experiment with\npeople experienced in the assignment of documents to CA sections.  The\nprogram assigned approximately 78% of the documents to the correct major\nsection groupings of CA and 67% of the correct sections or cross-references\nat a rate of 100 documents per second.",
    "67": "    Some of the automatic classification procedures used in information\nretrieval derive clusters of documents from an intermediate similarity\nmatrix, the computation of which involves comparing each of the documents\nin the collection with all of the others.  It has recently been suggested\nthat many of these comparisons, specifically those between documents\nhaving no terms in common, may be avoided by means of the uyse of an inverted\nfile to the document collection.  This communication shows that the\napproach will effect reductions in the number of interdocument comparisons\nonly if the documents are each indexed by a limited number of indexing\nterms; if exhaustive indexing is used, many document pairs will be compared\nseveral times over and the computation will be greater than when\nconventional approaches are used to generate the similarity matrix.",
    "68": "    The Use of a minicomputer in various phases of creating the thesaurus\nfor the National Information Center for Special Education Materials\n(NICSEM) database is described.  The minicomputer is used to collect,\nedit, and correct candidate thesaurus terms.  The use of the minicomputer\neases the process of grouping terms into files of similar concepts and\nfacilitates the generation of products useful in vocabulary review and in\nterm structuring.  Syndetic relations, indicated by assigning coded\nidentification numbers, are altered easily in the design phase to reflect\nrestructuring requirements.  Because thesaurus terms are already in machine-\nreadable form, it is simple to prepare print programs to provide permuted,\nalphabetic, hierarchical, and chart formatted term displays.  Overall, the\nuse of the minicomputer facilitates initial thesaurus entry development by\nreducing clerical effort, editorial staff decisions, and overall processing\ntimes.",
    "69": "    Decision Support Systems (DSS) represent a concept of the role of\ncomputers within the decision making process.  The term has become a\nrallying cry for researchers, practitioners, and managers concerned that\nManagement Science and Management Information Systems fields have become\nunnecessarily narrow in focus.  As with many rallying cries, the term is\nnot well defined.  For some writers, DSS simply mean interactive systems\nfor use by managers.  To others, the key issue is support, rather than\nsystem.  They focus on understanding and improving the decision process;\na DSS is then designed using any available and suitable technology. Some\nresearchers view DSS as a subfield of MIS, while others regard it as an\nextension of Management Science techniques.  The former define Decision\nSupport as providing managers with access to data and the latter as giving\nthem access to analytic models.\n\n    The key argument of this paper is that the term DSS is relevant to\nsituations where a \"final\" system can be developed only through an\nadaptive process of learning and evolution.  The design strategy must\nthen focus on getting finished; this is very different from Management\nScience and Data Processing approaches.  The research issued for DSS\ncenter around adaption and evolution; they include managerial learning\nrepresentation of tasks and user behavior, design architecture and\nstrategies for getting started.",
    "70": "    A new method is described to extract significant phrases in the title\nand the abstreact of scientific or technical documents.  The method is\nbased upon a text structure analysis and uses a relatively small dictionary.\nThe dictionary has been constructed based on the knowledge about concepts\nin the field of science or technology and some lexical knowledge.  For\nsignificant phrases and their component items may be used in different\nmeanings among the fields.  A text analysius approach has been applied to\nselect significant phrases as substantial and semantic information carriers\nof the contents of the abstract.\n\n    The results of the experiment for five sets of documents have shown\nthat the significant phrases are effectively extracted in all cases, and\nthe number of them for every document and the processing time is fairly\nsatisfactory.  The information representation of the document, partly\nusing the method, is discussed with relation to the construction of the\ndocument information retrieval system.",
    "71": "    Passage retrieval (already operational for lawyers) has advantages in\noutput form opver references retrieval and is economically feasible.\nPrevious experiments in passage retrieval for scientists have demonstrated\nrecall and false retrieval rates as good or better than those of present\nreference retrieval services.  The present experiment involved a greater\nvariety of forms of retrieval question.  In addition, search words were\nselected independently by two different people for each retrieval question.\nThe search words selected, in combination with the computer procedures used\nfor passage retrieval, produced average recall ratios of 72 and 67%,\nrespectively, for the two selectors.  The false retrieval rates were (except\nfor one predictably difficult question) respectively 13 and 10 falsely\nretrieved sentences per answer-paper retrieved.",
    "72": "    In this paper we describe a practical method of partial-match retrieval\nin very large data files.  A binary code word, called a descriptor, is\nassociated with each record of the file.  These record descriptors are\nthen used to form a derived descriptor for a block of several records,\nwhich will serve as an index for the block as a whole; hence, the name\n\"indexed descriptor files.\"\n\n    First the structure of these files is described and a simple, efficient\nretrieval algorithm is presented.  Then its expected behavior, in terms of\nstorage accesses, is analyzed in detail.  Two different file creation\nprocedures are sketched, and a number of ways in which the file organization\ncan be \"tuned\" to a particular application is suggested.",
    "73": "    Recenty technological advances and the success of OCLC, Inc. has led\nto the emergence of three additional nonprofit library networks:  the\nResearch Libraries Information Network (RLIN) of the Research Libraries\nGroup, Inc., the University of Toronto Library Automation System (UTLAS),\nand the Washington Library Network (WLN).  This paper examines the economic\nand technological factors affecting the evolution of these networks and\nalso explores the role of those state and regional (multistate) networks\nthat broker OCLC services.  The competitive and cooperative nature of\nnetwork relationships is a major theme of the discussion.",
    "74": "    A new type of natural language parser is presented.  The idea behind\nthis parser is to map input sentences into the deepest form of the\nrepresentation of their meaning and inferences, as is appropriate.  The\nparser is not distinct from an entire understanding system.  It uses an\nintegrated conception of inferences, scripts, plans and other knowledge to\naid in the parse.  Furthermore, it does not attempt to parse everything it\nsees.  Rather, it determines what is most interesting and concentrates on\nthat, ignoring the rest.",
    "75": "    This paper discusses the origins of library networks and traces their\ndevelopment in the United States in the late 1960s through the present.\nThe concept of resource sharing, with particular attention to the inter-\nlibrary loan and programs for the cooperative acquisition and storage of\nmaterials, is examined in relationship to library networks.  In particular,\nattention is given to the question of how these two major components of\nlibrary cooperation, which have tended to be separate, might become more\nclosely integrated.",
    "76": "    This paper presents a method of normalizations of English titles and\ntheir retrieval.  The title expressed by a noun phrase or a noun clause\nis converted to a function-expression by parsing.  For the retrieval with\na reasonable recall rate as well as a high precision rate, the function-\nexpression is transformed to a predicate-governor form, and then normalized\nto a standard form.  Therefrom, various items are extracted and recorded\nin a hierarchical tree-like inverted file.\n\n    In order to keep the recall rate in a reasonable value, several\nretrieval stages are implemented based on the key-term and case-label\nmatching.  The retrieval is controlled by the preciseness of the specification\nof case-labels for each key-term.",
    "77": "    A generalization of the notion of ATN grammar, called a cascaded ATN\n(CATN), is prescribed.  CATN's permit a decomposition of complex language\nunderstanding behavior into a sequence of cooperating ATN's with separate\ndomain of responsibility, where each stage (called an ATN transducer)\ntakes its input from the output of the previous stage.  The paper includes\nan extensive discjussion of the principles of factoring-conceptual\nfactoring reduces the number of places that a given fact needs to be\nrepresented in a grammar, and hypothesis factoring reduces the number\nof distinct hypotheses that have to be considered during parsing.",
    "78": "    Algorithms are given to process partially specified queries in a\ncompressed database system.  The proposed methods handle effectively\nqueries that use either whole words or word fragments as language elements.\nThe methods are compared and critically evaluated in terms of the design\nand retrieval costs.  The analyses show that the method which exploits the\ninterdependence of fragments as well as the relevance of fragments to\nrecords in the file has maximum design cost and least retrieval cost.",
    "79": "    From the detailed analysis of eight previously published mathematical\nmodels, a general formulation of Bradford's distribution can be deduced as\nfollows:  y = a log(x + c) + b, where y is the ratio of the cumulative\nfrequency of articles to the total number of articles and x is the ratio\nof the rank of journals to the total number of journals.  The parameters a, b,\nand c are the slope, the intercept, and the shift in a straight line to log rank,\nrespectively.  Each of the eight models is a special case of the general\nformulation and is one of five types of formulation.  In order to estimate\nthree unknown parameters, a statistical method using root-weighted square\nerror is proposed.  A comparative experiment using 11 databases suggests that\nthe fifth type of formulation with three unknown parameters is the best fit\nto the observed data.  A further experiment shows that the deletion of the\ndroop data leads to a more accurate value of parameters and less error.",
    "80": "    The lexical problems in large information systems are created by the\nnecessity of handling a great number of names and their interrelations.\nSuch lexical problems are not covered completely by the concept data\ndictionaries, which are mostly concerned with database scheme design rather\nthan the execution of operations.  In this paper we introduce our view of a\nlexical subsystem as a separate component in an information system architecture,\nto deal with linguistic and control functions concerning the lexical problems\nin local and network environments.  The lexical suybsystem is a special\nefficiently organized program package, which plays the role of a \"linguistic\nfilter\" in a broad sense for lexically incorrect queries, promotes integration\nof databases and information retrieval systems, and facilitates the creation\nof local information systems.  We hope that lexical subsystems can become\nproductive for any large, especially distributed, information system.",
    "81": "    The relational model has received increasing attention during the\npast decade.  Its advantages include simplicity, consistency, and a sound\ntheoretical basis.  In this article, the naturalness of viewing information\nretrieval relationally is demonstrated.  The relational model is presented,\nand the relational organization of a bibliographical database is shown.\nThe notion of normalization is introduced and first, second, third, and\nfourth normal forms are demonstrated.  Relational languages are discussed,\nincluding the relational calculus, relational algebra, and SEQUEL.\nNumerous examples pertinent to information retrieval are presented in these\nrelational languages.  Advantages of the relational approach to information\nretrieval are noted.",
    "82": "    This paper describes an architectural approach that provides information\nexchange across a broad spectrum of user applications and office automation\nofferings.  Some of the architectures described herein are currently\nimplemented in existing IBM products.  These and other architectures will\nprovide the basis for document interchange capability between products\nsuch as the IBM 5520 Administrative System, the IBM System/370 Distributed\nOffice Support System (DISOSS), and the IBM Displaywriter System.\nSpecifically described is a document distribution architecture and its\nassociated data streams and others.\n\n    A general overview of the architectures as opposed to a detailed\ntechnical description is provided.  The architectures described are\nprotocols for interchange between application processes; they do not\naddress the specific user interface.  The document distribution\narchitectures utilize SNA for data transmission and communications control\nfacilities.",
    "83": "    A technique is described for automatic reformulation of boolean\nqueries.  Based on patron relevance judgements of an initial retrieval,\nprevalence measures are derived for terms appearing in the retrieved set\nof documents that reflect a term's distribution among the relevant and\nnon-relevant documents.  These measures are then used to guide the\nconstruction of a boolean query for a subsequent retrieval.  To illustrate\nthe technique, a series of tests is described of its application to a small\ndata base in an experimental environment.  Results compare favourably with\nfeedback as employed in a SMART-type system.  MOre extensive testing is\nsuggested to validate the technique.",
    "84": "    This paper is intended to propose a new methodological approach to\nthe conception and development of natural language understanding systems.\nThis new contribution is supported by the design, implementation, and\nexperimentation of DONAU:  a general purpose domain oriented natural\nlanguage understanding system developed and presently running at the Milan\nPolytechnic Artificial Intelligence Project.  The system is based on a two\nlevel modular architecture intended to overcome the lack of flexibility and\ngenerality often pointed out in many existing systems, and to facilitate\nthe exchange of results and actual experiences between different projects.\nThe horizontal level allows an independent and parallel development of the\nsingle segments of the system (syntactic analyser, information extractor,\nlegality controller).  The vertical level ensures the possibility of changing\n(enlarging or redefining) the definition of the semantic domain on which each\nparticular version of the system is oriented and specialized in a simple,\nincremental, and user-oriented way.  In the paper the general architecture of\nthe system and the mode of operation of each segment are illustrated in\ndetail.  Linguistic models, knowledge representation, and parsing algorithms\nare described and illustrated by means of selected examples.  Performance\nevaluations of the system in the application version on data base inquiry are\nreported and discussed.  Promising directions for future research are presented\nin the conclusions.",
    "85": "    Approximate matching of strings is reviewed with the aim of\nsurveying techniques suitable for finding an item in a database when\nthere may be a spelling mistake or other error in the keyword.  The\nmethods found are classified as either equivalence or similarity problems.\nEquivalence problems are seen to be readily solved using canonical forms.\nFor similarity problems difference measures are surveyed, with a full\ndescription of the well-established dynamic programming method relating\nthis to the approach using probabilities and likelihoods.  Searches for\napproximate matches in large sets using a difference function are seen to\nbe an open problem still, though several promising ideas have been\nsuggested.  Approximate matching (error correction) during parsing is\nbriefly reviewed.",
    "86": "    A prototype system is created that integrates a microfiche catalog\ninto an online computer system for bibliographic control.  Costs and\noperational data are collected and analyzed.  The system permits the more\neconomical microfiche storage of catalog records than would be feasible\nfor comparable online magnetic disk storage.  Experimental tests\ndemonstrate the feasibility of the online microfiche catalog system for use\nin library technical services and retrieval of bibliographic data.  The\nprimary result of the project is the creation of a completely operational\nfacility, including all equipment, software, procedures, and data bases\nnecessary to demonstrate the system.  A second set of results is derived\nfrom the experimental use of the system and the evaluation of costs and\ntimes for various operations.  The cost effectiveness of the online microfiche\ncatalog is demonstrated.",
    "87": "    The question is asked whether it is feasible to use subsets of\nnatural languages as query languages for data bases in actual applications\nusing the question answering system \"USER SPECIALTY LANGUAGES\" (USL).\nMethods of evaluating a natural language based information system will\nbe discussed.  The results (error and language structure evaluation)\nsuggest how to form the general architecture of application systems which\nuse a subset of German as query language.",
    "88": "    In 1978 Collier presented some hypothetical data on economic aspects\nof the use of online services as compared with subscriptions to printed\nservices in libraries.  Collier's view of the economics of online searching\nseems misleadingly pessimistic because:\n\n1.  It looks only at costs but not at effectiveness in comparing the two\n    modes of access and searching.  An analysis combining cost and\n    effectiveness aspects (i.e., a cost-effectiveness analysis) would\n    give a completely different picture.\n\n2.  The way the cost data are presented is grossly unfair to the online\n    mode of access and use.\n\nThis work contains corrected information regarding online and printed\nservices in libraries.",
    "89": "    Many information scientists are concerned with the operation of\ndocument retrieval systems serving scientists in various fields.  The\nscientists served by these systems are often members of what have been called\ninvisible colleges, groups of scientists in frequent communication with\none another and involved with highly specialized subject matters.  Often\nsuch groups are considered to share an intellectual perspective regarding\nthis subject matter, which is sometimes referred to as a paradigm.\n\n    The purpose of this paper is to show how it is possible to identify\nparadigms, using the techniques of citation analysis.  I will operationalize\nthe notion of paradigm as a 'consensual structure of concepts in a field.'\nSuppose we have obtained a set of papers pertaining to some topic.  Already\nknowing something about the field, we read each text and mark passages in\nwhich certain specific concepts are used or discussed.  For example, we\nmight find that a concept designated 'A' appears in some sub-set of the\npapers.  Suppose further that we identify those papers in which concepts 'A'\nand 'B' are used together in the same papers in a certain specified manner.\nClearly not all concepts will combine in a natural way, and not all authors\ncombining concepts 'A' and 'B' will do so in the same way, though some\npredominant mode may emerge.  For a set of n concepts their structure is\ngiven by the totality of admissible combinations of concepts taken from\ntwo to n at a time.  The frequency with which a given combination occurs\nin the sample of papers on the topic is a measure of the degree of consensus\nregarding the particular concept combination within the corpus.  For\nconcepts taken two at a time, the structure can be displayed as a graph with\nconcepts as nodes and the relations between them represented as lines (arcs)\nconnecting the nodes.  This definition of concept structure is\nsimilar to the semantic network of artificial intelligence except that in\nour approach a measure of consensus weights each arc of the graph.",
    "90": "    One mode of online retrieval in Scisearch or Social Scisearch involves\nentering pairs of authors' names believed to be jointly cited by\nsubsequent writers and retrieving papers in which cocitations occur.  Six\npairs were formed with the names of four authors prominent in the social\nindicators movement (Bauer, Duncan, Land, and Sheldon).  Documents by the\nfour were not specified.  It was thought that the pair Duncan and Land\nwould retrieve papers in which indicator-type data would be integrated with\npath-analytic causal modeling.  All other pairs seemed likely to retrieve a\n\"general social indicators\" literature.  The 298 retrieved papers confirmed\nexpectattions.  It was found that 121 papers generally cited social indicators\n(SI) documents by the input authors and frequently had SI language in\ntheir titles.  Other signs of content also identified them as papers of\nthe SI movement.  The 177 papers retrieved on Duncan and Land generally\ncited causal modeling documents by the input pair and were path-analytic\nin nature.  As expected, they were relatively \"harder\" than the first\ngroup of papers, although the two groups are akin and are formally linked\nthrough citations in certain papers.  An additional result is that papers\nciting at least three of the input authors tend to be overviews of the SI\nmovement.",
    "91": "    The number of databases, records contained in databases and the online\nuse of databases has increased dramatically over the past several years,\nbringing the 1979 totals for bibliographic, bioliographic-related, and\nnatural language databases to 528.  These 528 databases contain 148 million\nrecords.  Some 4 million online searches were conducted via the major U.S.\nand Canadian systems in 1979.",
    "92": "    A method of iterative searching, using the results of one iteration search\nto formulate the next iteration search, was applied to a full-text database\nconsisting of some 2400 documents and 1,3000,000 text-words of Hebrew and\nAramaic.  The iterative method consists of clustering the documents returned\nin an iteration, using weighting by proximity and by frequency simultaneously.\nThe process produces searchonyms, which are terms synonymous to keywords in the\ncontext of a single query.  Augumenting or replacing keywords by searchonyms\nvia manual or automatic feedback leads to the formulation of the next iteration\nsearch.  The results of the experiment are consistent with those of an earlier\nsmall-scale experiment on an English database, and indicate that in contrast\nto global clustering where the size of matrices limits applications to small\ndatabases and improvements are doubtful, local metrical methods appear to be\nwell suited to arbitrarily large databases, improving precision and recall\nsimultaneously.  Further experiments using more test-queries run on even\nlarger databases should be made to collect further evidence as to the\nperformance of these methods.",
    "93": "    REFLES is a microcomputer-based system for data retrieval in library\nenvironments.  The problem of information retrieval is discussed from a\ntheoretical point of view, followed by an analysis of the reference process\nand data thereby gathered, leading to a description of REFLES in terms of\nits hardware and software.  REFLES, a prototype system at present, currently\nfunctions in a test environment.  Examples of data contained in the system\nand of its use are presented.  Future considerations and speculations on\nother versions of the system conclude the paper.",
    "94": "    A major deficiency of traditional Boolean systems is their inability to\nrepresent the varying degrees to which a document may be written on a subject.\nIn this article we isolate a number of criteria that should be met by any\nBoolean system generalized to have a weighting capability.  It is proven that\nonly one weighting rule satisfies these conditions--that associated with fuzzy-\nset theory--and that this weighting scheme satisfies most of the other\nproperties associated with Boolean algebra as well.  Probabilistic weighting\nis then introduced as an alternative approach and the two systems compared.\nIn the limit of zero/one weights, all systems considered converge to\ntraditional Boolean retrieval.",
    "95": "    Several papers have appeared that have analyzed recent developments\nin the problem of processing, in a document retrieval system, queries expressed\nas Boolean expressions.  The purpose of this paper is to continue that analysis.\nWe shall show that the concept of threshold values resolves the problems\ninherent with relevance weights.  Moreover, we shall explore possible evaluation\nmechanisms for retrieval of documents, based on fuzzy-set-theoretic\nconsiderations.",
    "96": "    There has been a good deal of work on information retrieval systems that\nhave continuous weights assigned to the index terms that describe the records\nin the database, and/or to the query terms that describe the user queries.\nRecent articles have analyzed retrieval systems with continuous weights of\neither type and/or with a Boolean structure for the queries.  They have also\nsuggested criteria which such systems ought to satisfy and record evaluation\nmechanisms which partially satisfy these criteria.  We offer a more careful\nanalysis, based on a generalization of the discrete weights.  We also look\nat the weights from an entirely different approach involving thresholds, and\nwe generate an improved evaluation mechanism which seems to fulfill a larger\nsubset of the desired criteria than previous mechanisms.  This new mechanism\nallows the user to attach a \"threshold\" to the query term.",
    "97": "    Online retrieval systems may be difficult to use, especially by end\nusers, because of heterogeneity and complexity.  Investigations have concerned\nthe concept of a translating computer interface as a means to simplify access\nto, and operation of, heterogeneous bibliographic retrieval systems and\ndatabases.  The interface allows users to make requests in a common language.\nThese requests are translated by the interface into the appropriate commands\nfor whatever system is being interrogated.  System responses may also be\ntransformed by the interface into a common form before being given to the\nusers.  Thus, the network of different systems is made to look like a single\n\"virtual\" system to the user.  The interface also provides instruction and\nother search aids for the user.  The philosophy, design, and implementation\nof an experimental interface named CONIT are described.",
    "98": "    The evaluation of the concept of a translating compuyter interface for\nsimplifying operation of multiple, heterogenous online bibliographic\nretrieval systems has been undertaken.  An experimental retrieval system,\nnamed CONIT, was built and tested under controlled conditions with\ninexperienced end users.  A detailed analysis of the experimental usages\nshowed that users were able to master interface operation sufficiently well\nto find relevant document references.  Success was attributed, in part,\nto a simple command language, adequate online instruction, and a simplified\nnatural-language, keyword/stem approach to searching.  It is concluded that\noperational interfaces of the type studied can provide for increased usability\nof existing system in a cost effective manner, especially for searchers.\nFurthermore, more advanced interfaces based on improved instruction and\nautomated search strategy techniques could further enhance retrieval\neffectiveness for a wide class of users.",
    "99": "    This paper notes the benefits accruing from interaction between computerized\nretrieval systems and micrographic retrieval systems.  It reviews current state\nof automated micrographic retrieval technology.  The conclusion is that with a\ncombination of advances in communications technology, and sophisticated indexing\ninput from libraries and information scientists, the new generation of automated\nmicrographs devices may constitute the on-line document retrieval systems of the\nfuture.",
    "100": "    Conventional information retrieval processes are largely based on data\nmovement, pointer manipulations and integer arithmetic; more refined retrieval\nalgorithms may in addition benefit from substantial computational power.\n\n    In the present study a number of parallel processing methods are described\nthat serve to enhance retrieval services.  In conventional retrieval\nenvironments parallel list processing and parallel search facilities are of\ngreatest interest.  In more advanced systems, the use of array processors\nalso proves beneficial.  Various information retrieval processes are examined\nand evidence is given to demonstrate the usefulness of parallel processing\nand fast computational facilities in information retrieval.",
    "101": "    The frequency characteristics of terms in the documents of a collection\nhave been used as indicators of term importance for content analysis and\nindexing purposes.  In particular, very rare or very frequent terms are\nnormally believed to be less effective than medium-frequency terms.  Recently\nautomatic indexing theories have been devised that use not only the term\nfrequency characteristics but also the relevance properties of the terms.\nThe major term-weighting theories are first briefly reviewed.  The term\nprecision and term utility weights that are based on the occurrence\ncharacteristics of the terms in the relevant, as opposed to the nonrelevant,\ndocuments of a collection are then introduced.  Methods are suggested for\nestimating the relevance properties of the terms based on their overall\noccurrence characteristics in the collection.  Finally, experimental\nevaluation results are shown comparing the weighting systems using the term\nrelevance properties with the more conventional frequency-based methodologies.",
    "102": "    This paper describes the design and implementation of an \"electronic filing\nmachine,\" a machine which is capable of storing large numbers of \"unstructured\"\ndocuments in such a way a particular document may be easily and quickly\nretrieved.  A functional distributed architecture permits the implementation\nof the system in a mixture of hardware and software.",
    "103": "    This paper tackles the problem of how one might select further search terms,\nusing relevance feedback, given the search terms in the query.  These search\nterms are extracted from a maximum spanning tree connecting all the terms in the\nindex term vocabulary.  A number of different spanning trees are generated from\na variety of association measures.  The retrieval effectiveness for the\ndifferent spanning trees is shown to be approximately the same.  Effectiveness\nis measured in terms of precision and recall, and the retrieval tests are done\non three different test collections.",
    "104": "    Indexing quality determines whether the information content of an indexed\ndocument is accurately represented.  Indexing effectiveness measures whether\nan indexed document is correctly retrieved every time it is relevant to a\nquery.  Measurement of these criteria is cumbersome and costly; data base\nproducers therefore prefer inter-indexer consistency as a measure of indexing\nquality or effectiveness.  The present article assesses the validity of this\nsubstitution in various environments.",
    "105": "    A set of experiments was conducted to determine the suitability of the\nColon Classification as a foundation for the automated analysis, representation\nand retrieval of primary information from the full text of documents.  Primary\ninformation is that information embodied in the text of a document, as opposed\nto secondary information which is generally in such forms as:  an abstract, a\ntable of contents, or an index.\n    Full text databases were created in two subject areas and queries solicited\nfrom specialists in each area.  An automated full text indexing system, along\nwith four automated passage retrieval systems, was created to test the various\nfeatures of the Colon Classification.  Two Boolean-based systems and one simple\nword occurrence system were created in order to compare the retrieval results\nagainst types of systems which are in more common use.  The systems' retrieval\nperformances were measured using recall and precision and the mean expected\nsearch length reduction factors.\n    Overall, it was found that the Colon Classification-based systems did not\nperform significantly better than the other systems.",
    "106": "    A study was carried out of the relationship between the vocabulary of\nuser queries and the vocabulary of documents relevant to the queries, and\nthe value of adding to the document description record in a retrieval system\nkeywords from previous queries for which the document had proved useful.\nTwo test databases incorporating user query keywords were implemented at\nthe School of Library and Information Science, University of Western\nOntario.  Clustering of the documents via title and user keywords, a\nstatistical analysis of title-user keyword co-occurrences, and retrieval\ntests were used to examine the effect of the added keywords.  Results\nshowed the impracticality of the procedure in an operational setting, but\nindicated the value of analyses with sample data in the development and\nmaintenance of keyword dictionaries and thesauri.",
    "107": "    A technique of online instruction and assistance to bibliographic data\nbase searchers called Individualized Instruction for Data Access (IIDA) is\nbeing developed by Drexel University.  IIDA assists searchers by providing\nfeedback based on real-time analysis while searches are being performed.\nExtensive help facilities which draw on this analysis are available to\nusers.  Much of the project's experimental work, as described elsewhere,\nis concerned with the process of searching and the behavior of searchers.\nThis paper will largely address itself to the project's computer system, which\nis being developed by subcontract with the Franklin Institute's Science\nInformation Services.",
    "108": "    It is shown that the mapping of a particular area of science, in this\ncase information science, can be done using authors as units of analysis and\nthe cocitations of pairs of authors as the variable that indicates their\n\"distances\" from each other.  The analysis assumes that the more two authors\nare cited together, the closer the relationship between them.  The raw data\nare cocitation counts drawn online from Social Scisearch (Social Sciences\nCitation Index) over the period 1972-1979.  GThe resulting map shows\n(1) identifiable author groups (akin to \"schools\") of information science,\n(2) locations of these groups with respect to each other, (3) the degree of\ncentrality and peripherality of authors within groups, (4) proximities of\nauthors within group and across group boundaries (\"border authors\" who seem\nto connect various areas of research), and (5) positions of authors with\nrespect to the map's axes, which were arbitrarily set spanning the most\ndivergent groups in order to aid interpretation.  Cocitation analysis of\nauthors offers a new technique that might contribute to the understanding of\nintellectual structure in the sciences and possibly in other areas to the\nextent that those areas rely on serial publications.  The technique\nestablishes authors, as well as documents, as an effective unit in\nanalyzing subject specialties.",
    "109": "    The \"Office of the Future,\" \"Office Technology,\" \"Word Processing,\"\n\"Electronic Mail,\" \"Electronic Communications,\" \"Convergence,\" \"Information\nManagement.\"  These are all terms included in the current list of buzz words\nused to describe current activities in the office technology area.  The high\nlevel of investment in factories and plants and the ever-increasing fight to\nimprove productivity by automating the dull, routine jobs are usually quoted\nand compared with the extremely low investment in improving and automating\nthe equally tedious routine jobs in the office environment; the investment\nin the factory is quoted as being ten times greater per employee than in the\noffice.  This, however, is changing rapidly and investment on a large scale\nis already taking place in manhy areas as present-day inflation bites hard,\nforcing many companies and organizations to take a much closer look at their\noffice operations.",
    "110": "    An automated document clustering procedure is described which does not\nrequire the use of an inter-document similarity matrix and which is independent\nof the order in which the documents are processed.  The procedure makes use of\nan initial set of clusters which is derived from certain of the terms in the\nindexing vocabulary used to characterise the documents in the file.  The\nretrieval effectiveness obtained using the clustered file is compared with that\nobtained from serial searching and from use of the single-linkage clustering\nmethod.",
    "111": "    A fast algorithm is described for comparing the lists of terms representing\ndocuments in automatic classification experiments.  The speed of the procedure\narises from the fact that all of the non-zero-valued coefficicents for a given\ndocument are identified together, using an inverted file to the terms in the\ndocument collection.  The complexity and running time of the algorithm are\ncompared with previously described procedures."
}